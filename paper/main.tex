% 10+2 Due Fri 28 Aug anywhere-on-earth
%
% ICSE 2019 Technical Track submission must not exceed 10 pages,
% including all text, figures, tables, and appendices; two additional pages
% containing only references are permitted.
%
% ICSE 2019 Technical Track will employ a double-blind review process.
% Thus, no submission may reveal its authorsâ€™ identities.
%
% https://2019.icse-conferences.org/track/icse-2019-Technical-Papers#Call-for-Papers

\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

%
\title{Blaming the Typeless: \\ Scalable, Human-Centric Python Localization}

\iffalse

\author{\IEEEauthorblockN{Benjamin Cosman}
\IEEEauthorblockA{\textit{UC San Digeo}\\
blcosman@eng.ecsd.edu}
\and
\IEEEauthorblockN{Leon Medvinsky}
\IEEEauthorblockA{\textit{UC San Digeo}\\
lmedvinsky@eng.ecsd.edu}
\and
\IEEEauthorblockN{Ranjit Jhala}
\IEEEauthorblockA{\textit{UC San Digeo}\\
jhala@cs.ecsd.edu}
\and
\IEEEauthorblockN{Westley Weimer}
\IEEEauthorblockA{\textit{University of Michigan}\\
weimerw@umich.edu}
}

\fi

\author{\IEEEauthorblockN{\emph{submitted for double-blind review}}}

\maketitle

\begin{abstract}
Abstract
\end{abstract}

\section{Introduction}

\emph{Placeholder Outline.} This text is an informal placeholder outline
only.

\emph{Identify an important problem.} Support the claim that Python fault
localization for possibly-ill-typed student fragments is an important
problem. Likely steps: fault localization is important, Python is
important, incomplete code is important. First, software engineering is
important and expensive; testing, maintenance, and debugging are the
dominant activities in SE; localization and triage are key steps. Second,
Python is increasingly used for pedagogy and industrial deployment, here
are some GitHub numbers about the rate of growth in Python projects
compared to C or Java, etc. Third, IDE tool use requires operating on code
fragments, here are some numbers from PythonTutor~\cite{Guo2013-vu}, generality, etc.

\emph{Identify the properties of a good solution.} Pick your favorite
three. Some candidates: accuracy (cite Parnin/Orso paper an indicate that
it must be found within top three, etc., since humans will not read long
lists), generality (must apply to student code and incomplete fragments),
scalability (must apply to hundreds of thousands of fragments, must present
real-time responses suitable for web/IDE use), agreement with subjective
judgments (must handle ``ambiguity'' the same way humans would when you
don't know whether to blame the use or the definition, etc.), efficiency
(must operate using a small number of dynamic runs, unlike Tarantula,
etc.).

\emph{Show that the current state of the art is inadequate.} For each $x$ of
\{manual debugging, Python's default error messages,
Mycroft/Sherrloc/Tarantula/whatever\}, show that $x$ lacks at least one of the
desired properties listed above.

\emph{Insights and special sauce.} What are the two or three good ideas
that we bring together to solve this problem? Some candidates: the use of
modern machine learning techniques (deep learning, etc.); the use of
tree-based contextual features to hit the sweet spot between syntax and semantics;
special handling of unsatisfied use-def type constraints (TBA); etc.

\emph{What is our proposal?} We propose XYZ, an algorithm to do ABC. It
takes as input DEF. It has stages P, Q and R. It produces as output GHI. It
provides guarantees JKL.

\emph{How will we evaluate it?} For each of the properties of a good
solution listed above, indicate how we will evaluate our contribution. What
evidence will we provide? Typically, for each property $x$, we support our
claim to $x$ with either a formal proof (e.g., our algorithm has $x$ by
construction), an empirical evaluation on software artifacts, or an
empirical evaluation on human subjects. In each case, indicate both the
evaluation metrics (e.g., if we care about efficiency, is it measured in
lines-per-second? if we care about precision, what is our non-standard
top-three metric) and success criteria (e.g., how will we define success?
what is the baseline we want to beat). For empirical evaluations, briefly
and implicitly argue that the results are likely to generalize by giving
the size of the sampled set.

\emph{Introduction wrap-up.} The contributions of this paper are as follows
...

\section{Motivating Example}

\section{Overview and Approach}

We present an algorithm for accurately localizing faults~\cite{tarantula} in
dynamically-typed Python programs that exhibit non-trivial uncaught runtime
exceptions. We do not consider syntax errors or references to undefined
variables. Our algorithm uses machine learning models based on static and
dynamic features to implicate suspicious expressions. Since studies have
found that voluminous fault localization output is not useful to
developers~\cite{orso-parnin,orso-parnin2013}, we focus on producing
Top-1 and Top-3 rankings. 

Our algorithm first extracts static and dynamic features from Python
program (Section~\ref{sec-features}). Next, using a labeled training
corpus, we learn a machine learning model over those features
(Section~\ref{sec-model}). Once the model has been learned, we localize
faults in new Python programs by extracting their features and applying the
model.

\subsection{Feature Extraction}
\label{sec-features} 

Our key insight is that FIXME-INSIGHT. Are a result, we make use of
static, dynamic and contextual information. Static features, such as FIXME,
are effective at capturing FIXME-INFORMATION. By contrast, dynamic
features, such as FIXME, support the modeling of FIXME. Finally, we also
include contextual information, such as FIXME, which allows our algorithm
to accurately handle FIXME. We consider the empirical justification of
these features in Section~\ref{sec-eval}. 

We calculate features for each statement and expression in the program. 

\begin{itemize}

\item \emph{Static / syntactic features}
\begin{enumerate}
    \item What kind of statement/expression it is, e.g. assignment / return
     / import (for statements) or variable / literal / application (expressions).
    \item Size (the number of AST nodes in the subtree rooted at this node)
\end{enumerate}

\item \emph{Dynamic features}
We run each program through an instrumented interpreter (i.e. a modified PythonTutor
backend, which itself is based on the BDB debugging library). This lets us
compute the following features:
\begin{enumerate}
    \item What type(s) does the expression have at runtime? (The values of this feature
    can be a type like int, or the special values "unknown" if the expression is
    never successfully evaluated and "multiple" if it changes type.)
    \item Is it part of the error slice?
    \item Is it the node at which the program actually crashes?
\end{enumerate}
(Since this interpreter works at the granularity of lines and we want to work with
expressions as well, we first convert each program to ANF.)

We compute the error slice by running the program and building a dependency
graph where node A depends on node B if either B defines a variable that A uses,
or B affects control flow allowing A to run.

We also check what uncaught exception is thrown by the program (TypeError,
KeyError, etc), and add that as a constant feature to all vectors derived from that program.

\item \emph{Contextual features} After all other features are computed so we have a
vector $v_e$ representing expression $e$, we set $v_e^{+context} = v_e \circ
v_p \circ v_{c_1} \circ v_{c_2} \circ v_{c_3}$ where $p$ is the expression's parent
in the AST and $c_i$ are its children. This allows us to recover some of the
program structure that would otherwise be completely lost when we convert the
structured program into an unstructured bag of feature vectors.

\item \emph{Label} Each feature vector is labeled by whether that expression/statement
changed between the crashing and fixed versions. (This is our proxy for whether
that node is to blame for the crash).

\end{itemize}

Each vector is then one-hot encoded (e.g. feature "Type : Int" becomes set
of features "Type-Int : 1", "Type-Bool : 0", "Type-Str : 0", etc.) for use with
standard machine learning tools. 

\subsection{Machine Learning and Modeling}
\label{sec-model} 

The models we train (inc. decision trees/forests,
MLP, GBM) can then rank expressions of a test program in order of how likely they
are to be the source of the bug, so we can compute Top-k accuracies: how often
is the true program change located in the model's first k outputs. 

\section{Evaluation}
\label{sec-eval} 

We conducted a large-scale empirical evaluation of our algorithm with the
aim of addressing a number of research questions: 
\begin{enumerate}

\item[RQ1]{Can we accurately localize non-trivial faults in Python
programs?} 

\item[RQ2]{Which features are the most important for Python fault
localization?} 

\item[RQ3]{FIXME}

\end{enumerate} 

\subsection{Data Set}

Our raw data consist of every Python 3 program that a user executed on
PythonTutor.com~\cite{Guo2013-vu} (not in ``live'' mode) during 2017, other
than those with syntax errors or undefined variables.  Each program which
crashes (throws an uncaught Python exception) is paired with the next
program (by the same user) that does not crash, under the assumption that
the latter is the fixed version of the former. We discard pairs where the
difference between crashing and fixed versions is too high (more than a
stddev above average), since these are most likely to be violations of that
assumption (i.e., the program that does not crash is unrelated to the
crashing program).

In our evaluation, we used FIXME as a training set and FIXME as a held-out
evaluation set. We employed cross-validation~\cite{kohavi} to help address
the potential threat of overfitting. 

\subsection{Methodology}

For these evaluations, we employ machine learning algorithm FIXME, which
provided the best balance of FIXME and FIXME (time? accuracy?) on our
training set. 

We report Top-1 and Top-3...

We define FIXME-ACCURACY to be FIXME. 

\subsection{RQ 1 --- Fault Localization Accuracy}
\subsection{RQ 2 --- Feature Predictive Power}
\subsection{RQ 3 --- FIXME}

\section{Related Work}

\section{Conclusion}

\bibliographystyle{abbrv}
\bibliography{nanomaly,sw}

\end{document}
